{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Parameter Identification for Mooney-Rivlin Hyperelastic Material\n\nThis example demonstrates inverse parameter identification for hyperelastic\nmaterials using experimental stress-strain data. We identify the Mooney-Rivlin\nmodel parameters from Treloar's classical rubber elasticity experiments.\n\n**Optimization**: scipy.optimize.differential_evolution (global optimizer)\n**Cost function**: Mean Squared Error on stress (sklearn.metrics.mean_squared_error)\n**Forward model**: simcoon hyperelastic stress functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import differential_evolution, fsolve\nfrom sklearn.metrics import mean_squared_error\nfrom simcoon import simmit as sim\nimport os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Methodology Overview\n\n**Inverse Problem Formulation**\n\nParameter identification is an inverse problem: given experimental observations\n(stress-strain data), we seek the material parameters that minimize the\ndiscrepancy between model predictions and experiments.\n\nThe optimization problem is:\n\n\\begin{align}\\boldsymbol{\\theta}^* = \\arg\\min_{\\boldsymbol{\\theta}} \\mathcal{L}(\\boldsymbol{\\theta})\\end{align}\n\nwhere $\\boldsymbol{\\theta}$ are the material parameters and\n$\\mathcal{L}$ is the cost function.\n\n**Cost Function: Stress-Based MSE**\n\nWe use the Mean Squared Error (MSE) computed on the first Piola-Kirchhoff\nstress $P_{11}$:\n\n\\begin{align}\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^{N} \\left( P_{11}^{\\text{model}}(\\lambda_i; \\boldsymbol{\\theta}) - P_{11}^{\\text{exp}}(\\lambda_i) \\right)^2\\end{align}\n\nThis stress-based metric directly measures the model's ability to predict\nmechanical response, which is the primary quantity of interest in constitutive\nmodeling.\n\n**Why Differential Evolution?**\n\nWe use ``scipy.optimize.differential_evolution`` because:\n\n1. **Global optimization**: Unlike gradient-based methods, it explores the\n   entire parameter space and avoids local minima\n2. **Derivative-free**: No gradients required, robust for non-smooth objectives\n3. **Bounded search**: Natural handling of physical parameter constraints\n4. **Robustness**: Less sensitive to initial guess compared to local methods\n\nFor hyperelastic models, the cost function landscape can be non-convex,\nmaking global optimization essential for reliable parameter identification.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mooney-Rivlin Constitutive Model\n\nThe Mooney-Rivlin model is a phenomenological hyperelastic model widely used\nfor rubber-like materials. The strain energy function is:\n\n\\begin{align}W = C_{10}(\\bar{I}_1 - 3) + C_{01}(\\bar{I}_2 - 3) + U(J)\\end{align}\n\nwhere:\n\n- $\\bar{I}_1, \\bar{I}_2$ are the first and second isochoric invariants\n  of the left Cauchy-Green tensor $\\mathbf{b} = \\mathbf{F}\\mathbf{F}^T$\n- $C_{10}, C_{01}$ are the material parameters to identify\n- $U(J) = \\kappa(J \\ln J - J + 1)$ is the volumetric contribution\n- $\\kappa$ is the bulk modulus (fixed, assuming near-incompressibility)\n\nThe Cauchy stress is computed as:\n\n\\begin{align}\\boldsymbol{\\sigma} = \\boldsymbol{\\sigma}_{\\text{iso}} + \\boldsymbol{\\sigma}_{\\text{vol}}\\end{align}\n\nwhere simcoon provides ``sigma_iso_hyper_invariants`` and ``sigma_vol_hyper``\nto compute these contributions from the strain energy derivatives:\n\n\\begin{align}\\frac{\\partial W}{\\partial \\bar{I}_1} = C_{10}, \\quad\n   \\frac{\\partial W}{\\partial \\bar{I}_2} = C_{01}, \\quad\n   \\frac{\\partial U}{\\partial J} = \\kappa \\ln J\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimental Data: Treloar's Rubber Experiments\n\nL.R.G. Treloar (1944) performed classical experiments on vulcanized rubber\nunder three loading conditions:\n\n1. **Uniaxial Tension (UT)**: $\\lambda_1 = \\lambda, \\lambda_2 = \\lambda_3 = \\lambda_t$\n2. **Pure Shear (PS)**: $\\lambda_1 = \\lambda, \\lambda_2 = \\lambda_t, \\lambda_3 = 1$\n3. **Equibiaxial Tension (ET)**: $\\lambda_1 = \\lambda_2 = \\lambda, \\lambda_3 = \\lambda_t$\n\nwhere $\\lambda_t$ is the transverse stretch determined by equilibrium\n(zero transverse stress). The data provides stretch $\\lambda$ and the\ncorresponding first Piola-Kirchhoff stress $P_{11}$ [MPa].\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def load_treloar_data(filepath: str) -> pd.DataFrame:\n    \"\"\"\n    Load Treloar experimental data.\n\n    The file contains columns for three loading cases:\n    - lambda_1, P1_MPa: Uniaxial tension\n    - lambda_2, P2_MPa: Pure shear\n    - lambda_3, P3_MPa: Equibiaxial tension\n\n    Parameters\n    ----------\n    filepath : str\n        Path to Treloar.txt data file\n\n    Returns\n    -------\n    pd.DataFrame\n        Experimental data with columns for each loading case\n    \"\"\"\n    df = pd.read_csv(\n        filepath,\n        sep=r\"\\s+\",\n        engine=\"python\",\n        names=[\"lambda_1\", \"P1_MPa\", \"lambda_2\", \"P2_MPa\", \"lambda_3\", \"P3_MPa\"],\n        header=0,\n    )\n    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Forward Model: Stress Prediction using simcoon\n\nThe forward model computes the first Piola-Kirchhoff stress for given\nmaterial parameters and stretch values. This is the core function that\nwill be called repeatedly during optimization.\n\n**Key steps:**\n\n1. For each stretch $\\lambda_1$, solve for the transverse stretch\n   $\\lambda_t$ that satisfies equilibrium (zero transverse stress)\n2. Construct the deformation gradient $\\mathbf{F}$\n3. Compute the left Cauchy-Green tensor $\\mathbf{b} = \\mathbf{F}\\mathbf{F}^T$\n   using ``sim.L_Cauchy_Green(F)``\n4. Compute strain energy derivatives for Mooney-Rivlin\n5. Compute Cauchy stress using ``sim.sigma_iso_hyper_invariants`` and\n   ``sim.sigma_vol_hyper``\n6. Convert to first Piola-Kirchhoff stress: $P_{11} = \\sigma_{11}/\\lambda_1$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def mooney_rivlin_pk1_stress(\n    C10: float,\n    C01: float,\n    kappa: float,\n    lambda_array: np.ndarray,\n    loading_case: str = \"UT\",\n) -> np.ndarray:\n    \"\"\"\n    Compute first Piola-Kirchhoff stress for Mooney-Rivlin material.\n\n    Uses simcoon's hyperelastic stress functions to compute the Cauchy stress\n    from the strain energy derivatives, then converts to PK1 stress.\n\n    Parameters\n    ----------\n    C10 : float\n        First Mooney-Rivlin parameter [MPa]\n    C01 : float\n        Second Mooney-Rivlin parameter [MPa]\n    kappa : float\n        Bulk modulus for volumetric response [MPa]\n    lambda_array : np.ndarray\n        Array of principal stretch values in the loading direction\n    loading_case : str\n        Type of loading: \"UT\" (uniaxial tension), \"PS\" (pure shear),\n        or \"ET\" (equibiaxial tension)\n\n    Returns\n    -------\n    np.ndarray\n        First Piola-Kirchhoff stress P_11 [MPa]\n    \"\"\"\n    PK1_stress = []\n    lambda_t_guess = 1.0  # Initial guess for transverse stretch\n\n    for lam in lambda_array:\n        # -----------------------------------------------------------------\n        # Step 1: Find transverse stretch satisfying equilibrium\n        # -----------------------------------------------------------------\n        def equilibrium_residual(lambda_t_vec):\n            \"\"\"Residual function for finding equilibrium transverse stretch.\"\"\"\n            lt = lambda_t_vec[0]\n\n            # Construct deformation gradient based on loading case\n            if loading_case == \"UT\":\n                # Uniaxial: F = diag(lambda, lambda_t, lambda_t)\n                F = np.diag([lam, lt, lt])\n                J = lam * lt**2\n            elif loading_case == \"PS\":\n                # Pure shear: F = diag(lambda, lambda_t, 1)\n                F = np.diag([lam, lt, 1.0])\n                J = lam * lt\n            elif loading_case == \"ET\":\n                # Equibiaxial: F = diag(lambda, lambda, lambda_t)\n                F = np.diag([lam, lam, lt])\n                J = lam**2 * lt\n            else:\n                raise ValueError(f\"Unknown loading case: {loading_case}\")\n\n            # Compute left Cauchy-Green tensor using simcoon\n            b = sim.L_Cauchy_Green(F)\n\n            # Mooney-Rivlin strain energy derivatives\n            dW_dI1_bar = C10\n            dW_dI2_bar = C01\n            dU_dJ = kappa * np.log(J)\n\n            # Compute Cauchy stress using simcoon functions\n            sigma_iso = sim.sigma_iso_hyper_invariants(\n                float(dW_dI1_bar), float(dW_dI2_bar), b, J, False\n            )\n            sigma_vol = sim.sigma_vol_hyper(dU_dJ, b, J, False)\n            sigma = sigma_iso + sigma_vol\n\n            # Return stress component that should be zero at equilibrium\n            if loading_case == \"UT\":\n                # sigma_22 = sigma_33 = 0\n                return 0.5 * (sigma[1, 1] + sigma[2, 2])\n            elif loading_case == \"PS\":\n                # sigma_22 = 0\n                return sigma[1, 1]\n            else:  # ET\n                # sigma_33 = 0\n                return sigma[2, 2]\n\n        # Solve for equilibrium transverse stretch\n        lambda_t = fsolve(equilibrium_residual, lambda_t_guess, full_output=False)[0]\n        lambda_t_guess = lambda_t  # Use as starting point for next iteration\n\n        # -----------------------------------------------------------------\n        # Step 2: Compute final stress state at equilibrium\n        # -----------------------------------------------------------------\n        if loading_case == \"UT\":\n            F = np.diag([lam, lambda_t, lambda_t])\n            J = lam * lambda_t**2\n        elif loading_case == \"PS\":\n            F = np.diag([lam, lambda_t, 1.0])\n            J = lam * lambda_t\n        else:  # ET\n            F = np.diag([lam, lam, lambda_t])\n            J = lam**2 * lambda_t\n\n        b = sim.L_Cauchy_Green(F)\n\n        # Strain energy derivatives\n        dW_dI1_bar = C10\n        dW_dI2_bar = C01\n        dU_dJ = kappa * np.log(J)\n\n        # Compute Cauchy stress\n        sigma_iso = sim.sigma_iso_hyper_invariants(\n            float(dW_dI1_bar), float(dW_dI2_bar), b, J, False\n        )\n        sigma_vol = sim.sigma_vol_hyper(dU_dJ, b, J, False)\n        sigma = sigma_iso + sigma_vol\n\n        # Convert Cauchy stress to PK1: P = J * sigma * F^{-T}\n        # For diagonal F: P_11 = sigma_11 / lambda_1\n        PK1_stress.append(sigma[0, 0] / lam)\n\n    return np.array(PK1_stress)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cost Function: Stress-Based Mean Squared Error\n\nThe cost function quantifies the discrepancy between model predictions and\nexperimental data. We use MSE computed on the PK1 stress values.\n\n**Normalized MSE (NMSE)**:\n\nWhen combining multiple loading cases with different stress magnitudes,\nwe can normalize by the variance to ensure balanced weighting:\n\n\\begin{align}\\text{NMSE} = \\frac{\\text{MSE}}{\\text{Var}(P^{\\text{exp}})}\\end{align}\n\nThis ensures that loading cases with smaller stress magnitudes are not\ndominated by cases with larger stresses during combined fitting.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def cost_function_mse(\n    params: np.ndarray,\n    lambda_exp: np.ndarray,\n    P_exp: np.ndarray,\n    kappa: float,\n    loading_case: str,\n    normalize: bool = False,\n) -> float:\n    \"\"\"\n    Compute MSE cost between model prediction and experimental stress data.\n\n    Parameters\n    ----------\n    params : np.ndarray\n        Material parameters [C10, C01]\n    lambda_exp : np.ndarray\n        Experimental stretch values\n    P_exp : np.ndarray\n        Experimental PK1 stress values [MPa]\n    kappa : float\n        Fixed bulk modulus [MPa]\n    loading_case : str\n        Loading type (\"UT\", \"PS\", or \"ET\")\n    normalize : bool\n        If True, divide MSE by variance of experimental data\n\n    Returns\n    -------\n    float\n        MSE or NMSE value\n    \"\"\"\n    C10, C01 = params\n\n    try:\n        # Predict stress using forward model\n        P_model = mooney_rivlin_pk1_stress(C10, C01, kappa, lambda_exp, loading_case)\n\n        # Compute MSE using sklearn\n        mse = mean_squared_error(P_exp, P_model)\n\n        if normalize:\n            variance = np.var(P_exp)\n            return mse / variance if variance > 1e-12 else mse\n        return mse\n\n    except Exception:\n        # Return large cost if computation fails (e.g., numerical issues)\n        return 1e10\n\n\ndef cost_function_combined(\n    params: np.ndarray, data_dict: dict, kappa: float, normalize: bool = True\n) -> float:\n    \"\"\"\n    Combined cost function for simultaneous fitting to multiple loading cases.\n\n    Parameters\n    ----------\n    params : np.ndarray\n        Material parameters [C10, C01]\n    data_dict : dict\n        Dictionary mapping loading case names to (lambda, P) tuples\n    kappa : float\n        Fixed bulk modulus [MPa]\n    normalize : bool\n        If True, use NMSE for balanced weighting across cases\n\n    Returns\n    -------\n    float\n        Sum of (N)MSE values over all loading cases\n    \"\"\"\n    total_cost = 0.0\n    for case_name, (lambda_exp, P_exp) in data_dict.items():\n        cost = cost_function_mse(params, lambda_exp, P_exp, kappa, case_name, normalize)\n        total_cost += cost\n    return total_cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameter Identification using Differential Evolution\n\n``scipy.optimize.differential_evolution`` is a stochastic global optimizer\nbased on evolutionary algorithms. Key parameters:\n\n- **bounds**: Search space for each parameter\n- **strategy**: Mutation strategy ('best1bin' works well for most problems)\n- **popsize**: Population size (larger = more thorough search)\n- **mutation**: Mutation constant (controls exploration vs exploitation)\n- **recombination**: Crossover probability\n- **polish**: If True, refines result with L-BFGS-B (local optimizer)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def identify_parameters(\n    lambda_exp: np.ndarray,\n    P_exp: np.ndarray,\n    kappa: float = 4000.0,\n    loading_case: str = \"UT\",\n    bounds: list = None,\n    normalize: bool = False,\n    seed: int = 42,\n    verbose: bool = True,\n) -> dict:\n    \"\"\"\n    Identify Mooney-Rivlin parameters using differential evolution.\n\n    Parameters\n    ----------\n    lambda_exp : np.ndarray\n        Experimental stretch values\n    P_exp : np.ndarray\n        Experimental PK1 stress values [MPa]\n    kappa : float\n        Fixed bulk modulus [MPa] (default: 4000 for near-incompressibility)\n    loading_case : str\n        Loading type (\"UT\", \"PS\", or \"ET\")\n    bounds : list\n        Parameter bounds [(C10_min, C10_max), (C01_min, C01_max)]\n    normalize : bool\n        If True, use normalized MSE\n    seed : int\n        Random seed for reproducibility\n    verbose : bool\n        Print optimization progress\n\n    Returns\n    -------\n    dict\n        Optimized parameters and optimization results\n    \"\"\"\n    if bounds is None:\n        bounds = [(0.01, 2.0), (-1.0, 1.0)]\n\n    if verbose:\n        print(f\"\\n{'=' * 60}\")\n        print(f\"Optimizing for {loading_case} loading case\")\n        print(f\"{'=' * 60}\")\n        print(f\"Parameter bounds: C10 in {bounds[0]}, C01 in {bounds[1]}\")\n        print(f\"Bulk modulus (fixed): kappa = {kappa} MPa\")\n\n    result = differential_evolution(\n        cost_function_mse,\n        bounds=bounds,\n        args=(lambda_exp, P_exp, kappa, loading_case, normalize),\n        strategy=\"best1bin\",\n        maxiter=500,\n        popsize=15,\n        tol=1e-8,\n        mutation=(0.5, 1.0),\n        recombination=0.7,\n        seed=seed,\n        polish=True,  # Refine with L-BFGS-B\n        disp=verbose,\n    )\n\n    C10_opt, C01_opt = result.x\n\n    if verbose:\n        print(f\"\\nOptimization completed!\")\n        print(f\"  C10 = {C10_opt:.6f} MPa\")\n        print(f\"  C01 = {C01_opt:.6f} MPa\")\n        print(f\"  Final MSE = {result.fun:.6e} MPa^2\")\n\n    return {\n        \"C10\": C10_opt,\n        \"C01\": C01_opt,\n        \"kappa\": kappa,\n        \"mse\": result.fun,\n        \"success\": result.success,\n        \"result\": result,\n    }\n\n\ndef identify_parameters_combined(\n    data_dict: dict,\n    kappa: float = 4000.0,\n    bounds: list = None,\n    normalize: bool = True,\n    seed: int = 42,\n    verbose: bool = True,\n) -> dict:\n    \"\"\"\n    Identify parameters by fitting to multiple loading cases simultaneously.\n\n    Using NMSE (normalized MSE) ensures balanced contribution from each\n    loading case, preventing cases with larger stress magnitudes from\n    dominating the optimization.\n\n    Parameters\n    ----------\n    data_dict : dict\n        Dictionary {case_name: (lambda_exp, P_exp)} for each loading case\n    kappa : float\n        Fixed bulk modulus [MPa]\n    bounds : list\n        Parameter bounds [(C10_min, C10_max), (C01_min, C01_max)]\n    normalize : bool\n        If True, use NMSE (recommended for combined fitting)\n    seed : int\n        Random seed\n    verbose : bool\n        Print progress\n\n    Returns\n    -------\n    dict\n        Optimized parameters and results\n    \"\"\"\n    if bounds is None:\n        bounds = [(0.01, 2.0), (-1.0, 1.0)]\n\n    if verbose:\n        print(f\"\\n{'=' * 60}\")\n        print(f\"Combined optimization for: {list(data_dict.keys())}\")\n        print(f\"{'=' * 60}\")\n        print(f\"Parameter bounds: C10 in {bounds[0]}, C01 in {bounds[1]}\")\n        print(f\"Bulk modulus (fixed): kappa = {kappa} MPa\")\n        print(f\"Using {'NMSE' if normalize else 'MSE'} for cost function\")\n\n    result = differential_evolution(\n        cost_function_combined,\n        bounds=bounds,\n        args=(data_dict, kappa, normalize),\n        strategy=\"best1bin\",\n        maxiter=500,\n        popsize=15,\n        tol=1e-8,\n        mutation=(0.5, 1.0),\n        recombination=0.7,\n        seed=seed,\n        polish=True,\n        disp=verbose,\n    )\n\n    C10_opt, C01_opt = result.x\n\n    if verbose:\n        print(f\"\\nOptimization completed!\")\n        print(f\"  C10 = {C10_opt:.6f} MPa\")\n        print(f\"  C01 = {C01_opt:.6f} MPa\")\n        print(f\"  Final combined cost = {result.fun:.6e}\")\n\n    return {\n        \"C10\": C10_opt,\n        \"C01\": C01_opt,\n        \"kappa\": kappa,\n        \"cost\": result.fun,\n        \"success\": result.success,\n        \"result\": result,\n    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization Functions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_fit_comparison(\n    lambda_exp: np.ndarray,\n    P_exp: np.ndarray,\n    params: dict,\n    loading_case: str,\n    title: str = None,\n    ax=None,\n):\n    \"\"\"\n    Plot experimental data vs model prediction.\n\n    Parameters\n    ----------\n    lambda_exp : np.ndarray\n        Experimental stretch values\n    P_exp : np.ndarray\n        Experimental PK1 stress values [MPa]\n    params : dict\n        Dictionary with 'C10', 'C01', 'kappa' keys\n    loading_case : str\n        Loading type\n    title : str\n        Plot title (optional)\n    ax : matplotlib.axes.Axes\n        Axes to plot on (creates new figure if None)\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes with the plot\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(8, 6))\n\n    # Model prediction on fine grid\n    lambda_model = np.linspace(1.0, lambda_exp.max() * 1.02, 200)\n    P_model = mooney_rivlin_pk1_stress(\n        params[\"C10\"], params[\"C01\"], params[\"kappa\"], lambda_model, loading_case\n    )\n\n    # Experimental data\n    ax.plot(\n        lambda_exp,\n        P_exp,\n        \"o\",\n        markersize=8,\n        markerfacecolor=\"red\",\n        markeredgecolor=\"black\",\n        label=\"Treloar experimental\",\n    )\n\n    # Model prediction\n    ax.plot(\n        lambda_model,\n        P_model,\n        \"-\",\n        linewidth=2,\n        color=\"blue\",\n        label=f\"Mooney-Rivlin (C10={params['C10']:.4f}, C01={params['C01']:.4f})\",\n    )\n\n    ax.set_xlabel(r\"Stretch $\\lambda$ [-]\", fontsize=12)\n    ax.set_ylabel(r\"PK1 Stress $P_{11}$ [MPa]\", fontsize=12)\n    ax.set_title(title or f\"{loading_case} - Parameter Identification\", fontsize=14)\n    ax.legend(loc=\"upper left\", fontsize=10)\n    ax.grid(True, alpha=0.3)\n\n    return ax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Execution\n\nWe demonstrate two identification strategies:\n\n1. **Individual fitting**: Optimize parameters separately for each loading case\n2. **Combined fitting**: Find a single parameter set that best fits all cases\n\nThe individual fits provide loading-case-specific parameters (useful for\nunderstanding material behavior), while combined fitting gives a universal\nparameter set for general use.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n    # Locate data file relative to script\n    # Try multiple approaches to find the data file (supports both direct\n    # execution and Sphinx-Gallery which does not define __file__)\n    data_filename = os.path.join(\"hyperelasticity\", \"comparison\", \"Treloar.txt\")\n    possible_paths = []\n\n    # Try using __file__ if available\n    try:\n        script_dir = os.path.dirname(os.path.abspath(__file__))\n        possible_paths.append(os.path.join(script_dir, \"..\", data_filename))\n    except NameError:\n        pass\n\n    # Try relative to current working directory (Sphinx-Gallery context)\n    possible_paths.append(os.path.join(os.getcwd(), \"..\", data_filename))\n    possible_paths.append(os.path.join(os.getcwd(), \"examples\", data_filename))\n\n    # Find first existing path\n    data_path = None\n    for path in possible_paths:\n        if os.path.exists(path):\n            data_path = path\n            break\n\n    if data_path is None:\n        raise FileNotFoundError(\n            f\"Could not find Treloar.txt data file. Searched: {possible_paths}\"\n        )\n\n    print(\"=\" * 70)\n    print(\" MOONEY-RIVLIN PARAMETER IDENTIFICATION\")\n    print(\" Using scipy.differential_evolution and sklearn.mean_squared_error\")\n    print(\"=\" * 70)\n\n    # -------------------------------------------------------------------------\n    # Load and prepare experimental data\n    # -------------------------------------------------------------------------\n    df = load_treloar_data(data_path)\n    print(f\"\\nLoaded Treloar data: {len(df)} data points\")\n\n    # Extract data for each loading case (remove NaN values)\n    ut_mask = ~df[\"lambda_1\"].isna() & ~df[\"P1_MPa\"].isna()\n    ps_mask = ~df[\"lambda_2\"].isna() & ~df[\"P2_MPa\"].isna()\n    et_mask = ~df[\"lambda_3\"].isna() & ~df[\"P3_MPa\"].isna()\n\n    lambda_ut = df.loc[ut_mask, \"lambda_1\"].values\n    P_ut = df.loc[ut_mask, \"P1_MPa\"].values\n\n    lambda_ps = df.loc[ps_mask, \"lambda_2\"].values\n    P_ps = df.loc[ps_mask, \"P2_MPa\"].values\n\n    lambda_et = df.loc[et_mask, \"lambda_3\"].values\n    P_et = df.loc[et_mask, \"P3_MPa\"].values\n\n    print(f\"\\nData summary:\")\n    print(\n        f\"  Uniaxial Tension (UT): {len(lambda_ut)} points, \"\n        f\"lambda in [{lambda_ut.min():.2f}, {lambda_ut.max():.2f}]\"\n    )\n    print(\n        f\"  Pure Shear (PS):       {len(lambda_ps)} points, \"\n        f\"lambda in [{lambda_ps.min():.2f}, {lambda_ps.max():.2f}]\"\n    )\n    print(\n        f\"  Equibiaxial (ET):      {len(lambda_et)} points, \"\n        f\"lambda in [{lambda_et.min():.2f}, {lambda_et.max():.2f}]\"\n    )\n\n    # Fixed bulk modulus (near-incompressible rubber)\n    kappa = 4000.0\n\n    # -------------------------------------------------------------------------\n    # Individual fitting for each loading case\n    # -------------------------------------------------------------------------\n    print(\"\\n\" + \"=\" * 70)\n    print(\" INDIVIDUAL FITTING (one parameter set per loading case)\")\n    print(\"=\" * 70)\n\n    params_ut = identify_parameters(lambda_ut, P_ut, kappa, \"UT\", verbose=True)\n    params_ps = identify_parameters(lambda_ps, P_ps, kappa, \"PS\", verbose=True)\n    params_et = identify_parameters(lambda_et, P_et, kappa, \"ET\", verbose=True)\n\n    # Reference values from literature (Steinmann et al., 2012)\n    print(\"\\n\" + \"-\" * 70)\n    print(\"Comparison with literature (Steinmann et al., 2012):\")\n    print(\"-\" * 70)\n    print(\n        f\"{'Case':<8} {'C10 (lit.)':<12} {'C10 (ident.)':<14} {'C01 (lit.)':<12} {'C01 (ident.)':<14}\"\n    )\n    print(\"-\" * 70)\n    print(\n        f\"{'UT':<8} {0.2588:<12.4f} {params_ut['C10']:<14.4f} {-0.0449:<12.4f} {params_ut['C01']:<14.4f}\"\n    )\n    print(\n        f\"{'PS':<8} {0.2348:<12.4f} {params_ps['C10']:<14.4f} {-0.065:<12.4f} {params_ps['C01']:<14.4f}\"\n    )\n    print(\n        f\"{'ET':<8} {0.1713:<12.4f} {params_et['C10']:<14.4f} {0.0047:<12.4f} {params_et['C01']:<14.4f}\"\n    )\n\n    # -------------------------------------------------------------------------\n    # Combined fitting\n    # -------------------------------------------------------------------------\n    print(\"\\n\" + \"=\" * 70)\n    print(\" COMBINED FITTING (single parameter set for all loading cases)\")\n    print(\"=\" * 70)\n\n    data_combined = {\n        \"UT\": (lambda_ut, P_ut),\n        \"PS\": (lambda_ps, P_ps),\n        \"ET\": (lambda_et, P_et),\n    }\n\n    params_combined = identify_parameters_combined(\n        data_combined, kappa=kappa, normalize=True, verbose=True\n    )\n\n    # -------------------------------------------------------------------------\n    # Visualization\n    # -------------------------------------------------------------------------\n    print(\"\\n\" + \"=\" * 70)\n    print(\" GENERATING PLOTS\")\n    print(\"=\" * 70)\n\n    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n\n    # Row 1: Individual fits\n    plot_fit_comparison(\n        lambda_ut, P_ut, params_ut, \"UT\", title=\"UT - Individual fit\", ax=axes[0, 0]\n    )\n    plot_fit_comparison(\n        lambda_ps, P_ps, params_ps, \"PS\", title=\"PS - Individual fit\", ax=axes[0, 1]\n    )\n    plot_fit_comparison(\n        lambda_et, P_et, params_et, \"ET\", title=\"ET - Individual fit\", ax=axes[0, 2]\n    )\n\n    # Row 2: Combined fit applied to all cases\n    plot_fit_comparison(\n        lambda_ut, P_ut, params_combined, \"UT\", title=\"UT - Combined fit\", ax=axes[1, 0]\n    )\n    plot_fit_comparison(\n        lambda_ps, P_ps, params_combined, \"PS\", title=\"PS - Combined fit\", ax=axes[1, 1]\n    )\n    plot_fit_comparison(\n        lambda_et, P_et, params_combined, \"ET\", title=\"ET - Combined fit\", ax=axes[1, 2]\n    )\n\n    fig.suptitle(\n        \"Mooney-Rivlin Parameter Identification using Treloar Data\\n\"\n        \"(Top: Individual fits, Bottom: Combined fit)\",\n        fontsize=14,\n        fontweight=\"bold\",\n    )\n    plt.tight_layout()\n\n    # -------------------------------------------------------------------------\n    # Summary\n    # -------------------------------------------------------------------------\n    print(\"\\n\" + \"=\" * 70)\n    print(\" SUMMARY OF IDENTIFIED PARAMETERS\")\n    print(\"=\" * 70)\n    print(f\"{'Case':<12} {'C10 [MPa]':>12} {'C01 [MPa]':>12} {'MSE [MPa^2]':>14}\")\n    print(\"-\" * 52)\n    print(\n        f\"{'UT':<12} {params_ut['C10']:>12.4f} {params_ut['C01']:>12.4f} {params_ut['mse']:>14.2e}\"\n    )\n    print(\n        f\"{'PS':<12} {params_ps['C10']:>12.4f} {params_ps['C01']:>12.4f} {params_ps['mse']:>14.2e}\"\n    )\n    print(\n        f\"{'ET':<12} {params_et['C10']:>12.4f} {params_et['C01']:>12.4f} {params_et['mse']:>14.2e}\"\n    )\n    print(\"-\" * 52)\n    print(\n        f\"{'Combined':<12} {params_combined['C10']:>12.4f} {params_combined['C01']:>12.4f} {params_combined['cost']:>14.2e}\"\n    )\n    print(\"=\" * 70)\n\n    print(\"\\nNote: The combined fit uses NMSE (normalized MSE) which explains\")\n    print(\"the different cost magnitude compared to individual MSE values.\")\n\n    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}